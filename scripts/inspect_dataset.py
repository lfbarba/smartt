#!/usr/bin/env python3
"""
Utility script to inspect HDF5 reconstruction datasets generated by smartt.

Usage:
    python inspect_dataset.py <path_to_hdf5_file>
"""

import sys
import h5py
import numpy as np
from pathlib import Path


def format_bytes(bytes_value):
    """Format bytes into human-readable form."""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if bytes_value < 1024.0:
            return f"{bytes_value:.2f} {unit}"
        bytes_value /= 1024.0
    return f"{bytes_value:.2f} TB"


def inspect_hdf5(filepath):
    """Inspect and display information about an HDF5 reconstruction dataset."""
    filepath = Path(filepath)
    
    if not filepath.exists():
        print(f"Error: File not found: {filepath}")
        return 1
    
    print("=" * 70)
    print(f"HDF5 Dataset Inspection: {filepath.name}")
    print("=" * 70)
    print(f"File path: {filepath}")
    print(f"File size: {format_bytes(filepath.stat().st_size)}")
    print()
    
    try:
        with h5py.File(filepath, 'r') as f:
            # Print all top-level items
            print("Contents:")
            print("-" * 70)
            for key in f.keys():
                item = f[key]
                if isinstance(item, h5py.Dataset):
                    print(f"  ðŸ“Š {key}")
                    print(f"     Shape: {item.shape}")
                    print(f"     Dtype: {item.dtype}")
                    if item.size > 0:
                        try:
                            data = item[()]
                            if isinstance(data, (int, float, np.number)):
                                print(f"     Value: {data}")
                            elif isinstance(data, np.ndarray) and data.size < 100:
                                print(f"     Values: {data}")
                        except Exception:
                            pass
                elif isinstance(item, h5py.Group):
                    print(f"  ðŸ“ {key}/ (Group)")
            
            print()
            
            # Print attributes
            if f.attrs:
                print("Attributes:")
                print("-" * 70)
                for key, value in f.attrs.items():
                    print(f"  {key}: {value}")
                print()
            
            # Detailed reconstruction info if available
            if 'reconstructions' in f:
                print("Reconstruction Dataset Details:")
                print("-" * 70)
                recon = f['reconstructions']
                print(f"  Total samples: {recon.shape[0]}")
                print(f"  Volume shape: {recon.shape[1:4]}")
                print(f"  Num coefficients: {recon.shape[4]}")
                print(f"  Total size: {format_bytes(recon.size * recon.dtype.itemsize)}")
                
                # Statistics for first sample
                if recon.shape[0] > 0:
                    sample = recon[0]
                    print(f"\n  First sample statistics:")
                    print(f"    Min: {sample.min():.6e}")
                    print(f"    Max: {sample.max():.6e}")
                    print(f"    Mean: {sample.mean():.6e}")
                    print(f"    Std: {sample.std():.6e}")
                
                print()
            
            # Metadata summary
            print("Dataset Metadata Summary:")
            print("-" * 70)
            
            metadata = {}
            for key in ['num_projections', 'ell_max', 'num_iterations', 
                       'maxiter', 'regularization_weight']:
                if key in f:
                    metadata[key] = f[key][()]
            
            if metadata:
                for key, value in metadata.items():
                    print(f"  {key}: {value}")
            else:
                print("  No metadata found")
            
            print()
            
            # Projection indices info if available
            if 'projection_indices' in f:
                print("Projection Indices:")
                print("-" * 70)
                indices = f['projection_indices']
                print(f"  Shape: {indices.shape}")
                print(f"  Indices per sample: {indices.shape[1] if len(indices.shape) > 1 else 'N/A'}")
                
                if indices.shape[0] > 0:
                    print(f"\n  First sample indices:")
                    first_indices = indices[0]
                    if len(first_indices) <= 20:
                        print(f"    {first_indices}")
                    else:
                        print(f"    {first_indices[:10]}...{first_indices[-10:]}")
                print()
            
            # Summary
            print("=" * 70)
            print("Summary:")
            print("-" * 70)
            if 'reconstructions' in f and metadata:
                n_samples = f['reconstructions'].shape[0]
                n_projs = metadata.get('num_projections', 'N/A')
                ell = metadata.get('ell_max', 'N/A')
                vol_shape = f['reconstructions'].shape[1:4]
                n_coeffs = f['reconstructions'].shape[4]
                
                print(f"  âœ“ {n_samples} reconstruction samples")
                print(f"  âœ“ Each using {n_projs} randomly selected projections")
                print(f"  âœ“ Volume dimensions: {vol_shape}")
                print(f"  âœ“ Spherical harmonics: ell_max={ell} â†’ {n_coeffs} coefficients")
                print(f"  âœ“ Total dataset size: {format_bytes(filepath.stat().st_size)}")
            else:
                print("  Dataset structure not recognized")
            print("=" * 70)
            
    except Exception as e:
        print(f"Error reading file: {e}")
        return 1
    
    return 0


def main():
    """Main entry point."""
    if len(sys.argv) != 2:
        print("Usage: python inspect_dataset.py <path_to_hdf5_file>")
        print("\nExample:")
        print("  python inspect_dataset.py data/training.h5")
        return 1
    
    filepath = sys.argv[1]
    return inspect_hdf5(filepath)


if __name__ == "__main__":
    sys.exit(main())
