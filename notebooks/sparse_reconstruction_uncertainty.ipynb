{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998a47c4",
   "metadata": {},
   "source": [
    "# Sparse Reconstruction Uncertainty Analysis\n",
    "\n",
    "This notebook analyzes the uncertainty in sparse tensor tomography reconstructions by:\n",
    "1. Computing a ground truth reconstruction using all available projections (240 angles)\n",
    "2. Fixing a sparse subset of 60 projections\n",
    "3. Repeatedly sampling 80% of these 60 projections (48 projections)\n",
    "4. Computing k reconstructions and analyzing their standard deviation\n",
    "5. Visualizing the uncertainty across spherical harmonic coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced09733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /das/work/units/pem/p20639/envs/p20639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from mumott.data_handling import DataContainer\n",
    "except:\n",
    "    !sh ../scripts/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51feaa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/myhome/smartt')\n",
    "sys.path.insert(0, '/das/home/barbaf_l/smartTT')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Import mumott modules\n",
    "from mumott.data_handling import DataContainer\n",
    "from mumott.methods.basis_sets import SphericalHarmonics\n",
    "from mumott.methods.projectors import SAXSProjector, SAXSProjectorCUDA\n",
    "from mumott.methods.residual_calculators import GradientResidualCalculator\n",
    "from mumott.optimization.loss_functions import SquaredLoss\n",
    "from mumott.optimization.optimizers import LBFGS\n",
    "from mumott.optimization.regularizers import Laplacian\n",
    "\n",
    "# Import custom functions\n",
    "# from smartt.data_processing import _perform_reconstruction\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data processing module for generating tensor tomography reconstruction datasets.\n",
    "\n",
    "This module provides functionality to load projection data, randomly sample subsets,\n",
    "perform mumott reconstructions, and save the results for machine learning training.\n",
    "\"\"\"\n",
    "\n",
    "import copy\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from typing import Union, Optional, List, Tuple, Dict\n",
    "from mumott.data_handling import DataContainer\n",
    "from mumott.methods.basis_sets import SphericalHarmonics\n",
    "from mumott.methods.projectors import SAXSProjector, SAXSProjectorCUDA\n",
    "from mumott.methods.residual_calculators import GradientResidualCalculator\n",
    "from mumott.optimization.loss_functions import SquaredLoss\n",
    "from mumott.optimization.optimizers import LBFGS\n",
    "from mumott.optimization.regularizers import Laplacian\n",
    "\n",
    "\n",
    "def _perform_reconstruction(\n",
    "    dc: DataContainer,\n",
    "    ell_max: int,\n",
    "    maxiter: int,\n",
    "    regularization_weight: float,\n",
    "    use_cuda: bool,\n",
    "    verbose: bool = False\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform a single spherical harmonic reconstruction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dc : DataContainer\n",
    "        The data container with projections.\n",
    "    ell_max : int\n",
    "        Maximum degree for spherical harmonics expansion.\n",
    "    maxiter : int\n",
    "        Maximum number of iterations for the LBFGS optimizer.\n",
    "    regularization_weight : float\n",
    "        Weight for the Laplacian regularization term.\n",
    "    use_cuda : bool\n",
    "        Whether to use CUDA for computation.\n",
    "    verbose : bool, default=False\n",
    "        Whether to print progress information.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The reconstruction as a numpy array of shape (*volume_shape, num_coeffs).\n",
    "    \"\"\"\n",
    "    basis_set = SphericalHarmonics(ell_max=ell_max)\n",
    "    \n",
    "    # Create projector (CUDA or CPU)\n",
    "    if use_cuda:\n",
    "        projector = SAXSProjectorCUDA(dc.geometry)\n",
    "    else:\n",
    "        projector = SAXSProjector(dc.geometry)\n",
    "    \n",
    "    residual_calculator = GradientResidualCalculator(\n",
    "        data_container=dc,\n",
    "        basis_set=basis_set,\n",
    "        projector=projector\n",
    "    )\n",
    "    \n",
    "    loss_function = SquaredLoss(residual_calculator)\n",
    "    regularizer = Laplacian()\n",
    "    loss_function.add_regularizer(\n",
    "        name='laplacian',\n",
    "        regularizer=regularizer,\n",
    "        regularization_weight=regularization_weight\n",
    "    )\n",
    "    \n",
    "    optimizer = LBFGS(loss_function, maxiter=maxiter)\n",
    "    \n",
    "    # Run optimization\n",
    "    if verbose:\n",
    "        print(\"Running optimization...\")\n",
    "    results = optimizer.optimize()\n",
    "    \n",
    "    # Extract reconstruction\n",
    "    if isinstance(results, dict):\n",
    "        if 'x' in results:\n",
    "            reconstruction = results['x']\n",
    "        elif 'reconstruction' in results:\n",
    "            reconstruction = results['reconstruction']\n",
    "        elif 'coefficients' in results:\n",
    "            reconstruction = results['coefficients']\n",
    "        else:\n",
    "            for key, value in results.items():\n",
    "                if isinstance(value, (np.ndarray, torch.Tensor)) or hasattr(value, 'shape'):\n",
    "                    reconstruction = value\n",
    "                    if verbose:\n",
    "                        print(f\"Using key '{key}' as reconstruction\")\n",
    "                    break\n",
    "            else:\n",
    "                raise ValueError(f\"Could not find reconstruction in results. Keys: {list(results.keys())}\")\n",
    "    elif hasattr(results, 'reconstruction'):\n",
    "        reconstruction = results.reconstruction\n",
    "    else:\n",
    "        reconstruction = results\n",
    "    \n",
    "    # Convert to numpy if it's a torch tensor\n",
    "    if torch.is_tensor(reconstruction):\n",
    "        reconstruction = reconstruction.cpu().numpy()\n",
    "    \n",
    "    # Ensure it's a numpy array\n",
    "    if not isinstance(reconstruction, np.ndarray):\n",
    "        reconstruction = np.asarray(reconstruction)\n",
    "    \n",
    "    return reconstruction.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe38a02e",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_path = '/myhome/data/smartt/shared/frogbone_test/dataset_qbin_0000.h5'\n",
    "data_path = '/das/home/barbaf_l/p20639/Mads/frog/frogbone/dataset_qbin_0000.h5'\n",
    "\n",
    "# Reconstruction parameters\n",
    "ell_max = 8\n",
    "maxiter = 20\n",
    "regularization_weight = 0 # usually 1.0 \n",
    "use_cuda = True  # Set to False if CUDA is not available\n",
    "\n",
    "# Sparse sampling parameters\n",
    "num_projections_sparse = 10  # Fixed sparse subset\n",
    "subsample_fraction = 0.9     # Sample 90% of the 10 projections\n",
    "num_subsamples = int(subsample_fraction * num_projections_sparse)          # 80% of 20\n",
    "num_experiments = 5         # Number of random subsampling experiments\n",
    "\n",
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  ell_max: {ell_max}\")\n",
    "print(f\"  Fixed sparse subset: {num_projections_sparse} projections\")\n",
    "print(f\"  Subsample size: {num_subsamples} projections (80%)\")\n",
    "print(f\"  Number of experiments: {num_experiments}\")\n",
    "print(f\"  Using {'CUDA' if use_cuda else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813f969",
   "metadata": {},
   "source": [
    "## 2. Load Dataset and Compute Ground Truth\n",
    "\n",
    "We'll compute the ground truth reconstruction using all 240 available projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data container\n",
    "print(\"Loading data container...\")\n",
    "dc_full = DataContainer(data_path, nonfinite_replacement_value=0)\n",
    "total_projections = len(dc_full.projections)\n",
    "\n",
    "print(f\"\\nDataset information:\")\n",
    "print(f\"  Total projections available: {total_projections}\")\n",
    "print(f\"  Volume shape: {dc_full.geometry.volume_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10f0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ground truth reconstruction with all projections\n",
    "print(f\"\\nComputing ground truth reconstruction with all {total_projections} projections...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "ground_truth = _perform_reconstruction(\n",
    "    dc=dc_full,\n",
    "    ell_max=ell_max,\n",
    "    maxiter=maxiter,\n",
    "    regularization_weight=regularization_weight,\n",
    "    use_cuda=use_cuda,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nGround truth shape: {ground_truth.shape}\")\n",
    "volume_shape = ground_truth.shape[:3]\n",
    "num_coeffs = ground_truth.shape[3]\n",
    "print(f\"Volume shape: {volume_shape}\")\n",
    "print(f\"Number of coefficients: {num_coeffs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fee72f",
   "metadata": {},
   "source": [
    "## 3. Select Fixed Sparse Subset\n",
    "\n",
    "Randomly select 60 projections from the full set. This subset will remain fixed for all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd22a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select fixed sparse subset of 60 projections\n",
    "np.random.seed(seed)\n",
    "fixed_sparse_indices = np.random.choice(\n",
    "    total_projections,\n",
    "    size=num_projections_sparse,\n",
    "    replace=False\n",
    ")\n",
    "fixed_sparse_indices = np.arange(num_projections_sparse)\n",
    "\n",
    "fixed_sparse_indices = np.sort(fixed_sparse_indices)\n",
    "\n",
    "fixed_sparse_indices = np.linspace(0, 50, num_projections_sparse, dtype=int)\n",
    "\n",
    "print(f\"Fixed sparse subset (60 projections):\")\n",
    "print(f\"  Indices: {fixed_sparse_indices[:10]}...{fixed_sparse_indices[-10:]}\")\n",
    "print(f\"  Min: {fixed_sparse_indices.min()}, Max: {fixed_sparse_indices.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf7c650",
   "metadata": {},
   "source": [
    "## 4. Run Multiple Sparse Reconstruction Experiments\n",
    "\n",
    "For each experiment:\n",
    "1. Randomly sample 80% of the fixed 60 projections (48 projections)\n",
    "2. Perform sparse reconstruction with these 48 projections\n",
    "3. Store the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4be673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocate array to store all reconstructions\n",
    "all_reconstructions = np.zeros(\n",
    "    (num_experiments, *volume_shape, num_coeffs),\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "# Store the indices used in each experiment\n",
    "subsample_indices_list = []\n",
    "\n",
    "print(f\"\\nRunning {num_experiments} sparse reconstruction experiments...\")\n",
    "print(f\"Each experiment uses {num_subsamples} randomly sampled projections from the fixed subset of 60.\\n\")\n",
    "\n",
    "for exp_idx in tqdm(range(num_experiments), desc=\"Experiments\"):\n",
    "    # Randomly sample 80% of the fixed sparse subset\n",
    "    subsample_indices = np.random.choice(\n",
    "        fixed_sparse_indices,\n",
    "        size=num_subsamples,\n",
    "        replace=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    subsample_indices = np.sort(subsample_indices)\n",
    "    subsample_indices_list.append(subsample_indices)\n",
    "    \n",
    "    # Create a fresh data container with only the subsampled projections\n",
    "    dc_subsample = DataContainer(data_path, nonfinite_replacement_value=0)\n",
    "    \n",
    "    # Remove projections not in the subsample\n",
    "    all_indices = np.arange(total_projections)\n",
    "    indices_to_delete = [i for i in all_indices if i not in subsample_indices]\n",
    "    \n",
    "    for i in sorted(indices_to_delete, reverse=True):\n",
    "        del dc_subsample.projections[i]\n",
    "    \n",
    "    # Perform reconstruction\n",
    "    reconstruction = _perform_reconstruction(\n",
    "        dc=dc_subsample,\n",
    "        ell_max=ell_max,\n",
    "        maxiter=maxiter,\n",
    "        regularization_weight=regularization_weight,\n",
    "        use_cuda=use_cuda,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Store reconstruction\n",
    "    all_reconstructions[exp_idx] = reconstruction\n",
    "    \n",
    "    # Clean up\n",
    "    del dc_subsample, reconstruction\n",
    "\n",
    "print(f\"\\nCompleted {num_experiments} experiments.\")\n",
    "print(f\"All reconstructions shape: {all_reconstructions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59770d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 10 slices of all_reconstructions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    if i < num_experiments:\n",
    "        slice_data = all_reconstructions[i, 32, :, :, 0]\n",
    "        im = axes[i].imshow(slice_data, cmap='viridis')\n",
    "        axes[i].set_title(f'Experiment {i}', fontsize=11, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "        plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "    else:\n",
    "        axes[i].axis('off')\n",
    "\n",
    "fig.suptitle('First 10 Reconstructions at z=32, coefficient 0', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db19b5c",
   "metadata": {},
   "source": [
    "## 5. Compute Standard Deviation Across Experiments\n",
    "\n",
    "Calculate the standard deviation across all experiments to quantify reconstruction uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7867910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation across experiments\n",
    "mean_reconstruction = np.mean(all_reconstructions, axis=0)\n",
    "std_reconstruction = np.std(all_reconstructions, axis=0)\n",
    "\n",
    "print(f\"Mean reconstruction shape: {mean_reconstruction.shape}\")\n",
    "print(f\"Std reconstruction shape: {std_reconstruction.shape}\")\n",
    "\n",
    "# Compute statistics\n",
    "print(f\"\\nStandard deviation statistics (across all voxels and coefficients):\")\n",
    "print(f\"  Mean std: {np.mean(std_reconstruction):.6f}\")\n",
    "print(f\"  Median std: {np.median(std_reconstruction):.6f}\")\n",
    "print(f\"  Min std: {np.min(std_reconstruction):.6f}\")\n",
    "print(f\"  Max std: {np.max(std_reconstruction):.6f}\")\n",
    "\n",
    "# Per-coefficient statistics\n",
    "print(f\"\\nPer-coefficient std statistics:\")\n",
    "for coeff_idx in range(num_coeffs):\n",
    "    coeff_std = std_reconstruction[..., coeff_idx]\n",
    "    print(f\"  Coefficient {coeff_idx:2d}: mean={np.mean(coeff_std):.6f}, \"\n",
    "          f\"median={np.median(coeff_std):.6f}, max={np.max(coeff_std):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc6afe",
   "metadata": {},
   "source": [
    "## 6. Visualize Standard Deviation Slices\n",
    "\n",
    "Plot slices through the 3D standard deviation volume for different spherical harmonic coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf699774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select coefficients to visualize\n",
    "# Coefficient 0 is l=0 (isotropic), then l=2, l=4, l=6, l=8\n",
    "coeffs_to_plot = [0, 1, 6, 15, 28, 44]  # Start of each l value: l=0, l=2, l=4, l=6, l=8, last coeff\n",
    "coeff_labels = ['ℓ=0 (iso)', 'ℓ=2, m=-2', 'ℓ=4, m=-4', 'ℓ=6, m=-6', 'ℓ=8, m=-8', 'ℓ=8, m=8']\n",
    "\n",
    "# Select middle slice\n",
    "mid_z = volume_shape[2] // 2\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (coeff_idx, label) in enumerate(zip(coeffs_to_plot, coeff_labels)):\n",
    "    std_slice = std_reconstruction[:, :, mid_z, coeff_idx]\n",
    "    \n",
    "    im = axes[idx].imshow(std_slice.T, cmap='hot', origin='lower')\n",
    "    axes[idx].set_title(f'Std Dev - {label}\\n(z={mid_z})', fontsize=12, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "    plt.colorbar(im, ax=axes[idx], fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.suptitle(f'Standard Deviation Across {num_experiments} Reconstructions\\n'\n",
    "             f'(Each with {num_subsamples} random projections from fixed subset of {num_projections_sparse})',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d37d2",
   "metadata": {},
   "source": [
    "## 7. Multiple Z-Slices for Selected Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiple z-slices for the isotropic component (l=0)\n",
    "coeff_idx = 1\n",
    "z_slices = [volume_shape[2]//4, volume_shape[2]//2, 3*volume_shape[2]//4]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, z in enumerate(z_slices):\n",
    "    std_slice = std_reconstruction[:, :, z, coeff_idx]\n",
    "    \n",
    "    im = axes[idx].imshow(std_slice.T, cmap='hot', origin='lower')\n",
    "    axes[idx].set_title(f'Std Dev - ℓ=0 (isotropic)\\nz={z}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "    plt.colorbar(im, ax=axes[idx], fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.suptitle(f'Standard Deviation Across Different Z-Slices', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f120830",
   "metadata": {},
   "source": [
    "## 8. Compare Mean Reconstruction vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e2838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare mean of sparse reconstructions to ground truth\n",
    "coeff_idx = 2  # Isotropic component\n",
    "mid_z = volume_shape[2] // 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Determine shared colorbar limits\n",
    "vmin = min(mean_reconstruction[:, :, mid_z, coeff_idx].min(),\n",
    "           ground_truth[:, :, mid_z, coeff_idx].min())\n",
    "vmax = max(mean_reconstruction[:, :, mid_z, coeff_idx].max(),\n",
    "           ground_truth[:, :, mid_z, coeff_idx].max())\n",
    "\n",
    "# Mean reconstruction\n",
    "im0 = axes[0].imshow(mean_reconstruction[:, :, mid_z, coeff_idx].T,\n",
    "                     cmap='viridis', vmin=vmin, vmax=vmax, origin='lower')\n",
    "axes[0].set_title(f'Mean of {num_experiments} Sparse\\nReconstructions (ℓ=0)', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Ground truth\n",
    "im1 = axes[1].imshow(ground_truth[:, :, mid_z, coeff_idx].T,\n",
    "                     cmap='viridis', vmin=vmin, vmax=vmax, origin='lower')\n",
    "axes[1].set_title(f'Ground Truth\\n(All {total_projections} projections, ℓ=0)', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Difference\n",
    "diff = mean_reconstruction[:, :, mid_z, coeff_idx] - ground_truth[:, :, mid_z, coeff_idx]\n",
    "im2 = axes[2].imshow(diff.T, cmap='RdBu_r', origin='lower',\n",
    "                     vmin=-np.abs(diff).max(), vmax=np.abs(diff).max())\n",
    "axes[2].set_title('Difference\\n(Mean - Ground Truth)', fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.suptitle(f'Mean Sparse Reconstruction vs Ground Truth (z={mid_z})', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute error metrics\n",
    "mse = np.mean((mean_reconstruction - ground_truth)**2)\n",
    "mae = np.mean(np.abs(mean_reconstruction - ground_truth))\n",
    "print(f\"\\nError metrics (Mean reconstruction vs Ground truth):\")\n",
    "print(f\"  MSE: {mse:.6f}\")\n",
    "print(f\"  MAE: {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c48af",
   "metadata": {},
   "source": [
    "## 9. Histogram of Standard Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89badf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of standard deviations for different coefficients\n",
    "coeffs_to_plot = [0, 1, 6, 15, 28, 44]\n",
    "coeff_labels = ['ℓ=0', 'ℓ=2, m=-2', 'ℓ=4, m=-4', 'ℓ=6, m=-6', 'ℓ=8, m=-8', 'ℓ=8, m=8']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (coeff_idx, label) in enumerate(zip(coeffs_to_plot, coeff_labels)):\n",
    "    std_flat = std_reconstruction[..., coeff_idx].flatten()\n",
    "    \n",
    "    axes[idx].hist(std_flat, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    axes[idx].set_xlabel('Standard Deviation', fontsize=10)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[idx].set_title(f'{label}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_std = np.mean(std_flat)\n",
    "    median_std = np.median(std_flat)\n",
    "    axes[idx].axvline(mean_std, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_std:.4f}')\n",
    "    axes[idx].axvline(median_std, color='orange', linestyle='--', linewidth=2, label=f'Median: {median_std:.4f}')\n",
    "    axes[idx].legend(fontsize=9)\n",
    "\n",
    "fig.suptitle(f'Distribution of Standard Deviations Across Voxels', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bed6a",
   "metadata": {},
   "source": [
    "## 10. Coefficient-wise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e92767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean std for each coefficient\n",
    "mean_std_per_coeff = np.array([np.mean(std_reconstruction[..., i]) for i in range(num_coeffs)])\n",
    "median_std_per_coeff = np.array([np.median(std_reconstruction[..., i]) for i in range(num_coeffs)])\n",
    "max_std_per_coeff = np.array([np.max(std_reconstruction[..., i]) for i in range(num_coeffs)])\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "x = np.arange(num_coeffs)\n",
    "\n",
    "# Mean std per coefficient\n",
    "axes[0].bar(x, mean_std_per_coeff, color='steelblue', alpha=0.7)\n",
    "axes[0].set_xlabel('Coefficient Index', fontsize=11)\n",
    "axes[0].set_ylabel('Mean Std Dev', fontsize=11)\n",
    "axes[0].set_title('Mean Standard Deviation per Coefficient', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Median std per coefficient\n",
    "axes[1].bar(x, median_std_per_coeff, color='orange', alpha=0.7)\n",
    "axes[1].set_xlabel('Coefficient Index', fontsize=11)\n",
    "axes[1].set_ylabel('Median Std Dev', fontsize=11)\n",
    "axes[1].set_title('Median Standard Deviation per Coefficient', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Max std per coefficient\n",
    "axes[2].bar(x, max_std_per_coeff, color='crimson', alpha=0.7)\n",
    "axes[2].set_xlabel('Coefficient Index', fontsize=11)\n",
    "axes[2].set_ylabel('Max Std Dev', fontsize=11)\n",
    "axes[2].set_title('Maximum Standard Deviation per Coefficient', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add ℓ value labels\n",
    "for ax in axes:\n",
    "    ax.set_xticks([0, 1, 6, 15, 28])\n",
    "    ax.set_xticklabels(['ℓ=0', 'ℓ=2', 'ℓ=4', 'ℓ=6', 'ℓ=8'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde2cb4",
   "metadata": {},
   "source": [
    "## 11. Relative Uncertainty\n",
    "\n",
    "Compute relative uncertainty (std / mean) to understand uncertainty relative to signal strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d927eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute relative uncertainty (coefficient of variation)\n",
    "# Add small epsilon to avoid division by zero\n",
    "epsilon = 1e-10\n",
    "relative_uncertainty = std_reconstruction / (np.abs(mean_reconstruction) + epsilon)\n",
    "\n",
    "# Clip extreme values for visualization\n",
    "relative_uncertainty_clipped = np.clip(relative_uncertainty, 0, 5)\n",
    "\n",
    "print(f\"Relative uncertainty statistics:\")\n",
    "print(f\"  Mean: {np.mean(relative_uncertainty):.4f}\")\n",
    "print(f\"  Median: {np.median(relative_uncertainty):.4f}\")\n",
    "print(f\"  90th percentile: {np.percentile(relative_uncertainty, 90):.4f}\")\n",
    "print(f\"  99th percentile: {np.percentile(relative_uncertainty, 99):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f492f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relative uncertainty for selected coefficients\n",
    "coeffs_to_plot = [0, 1, 6, 15, 28, 44]\n",
    "coeff_labels = ['ℓ=0', 'ℓ=2, m=-2', 'ℓ=4, m=-4', 'ℓ=6, m=-6', 'ℓ=8, m=-8', 'ℓ=8, m=8']\n",
    "mid_z = volume_shape[2] // 2\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (coeff_idx, label) in enumerate(zip(coeffs_to_plot, coeff_labels)):\n",
    "    rel_unc_slice = relative_uncertainty_clipped[:, :, mid_z, coeff_idx]\n",
    "    \n",
    "    im = axes[idx].imshow(rel_unc_slice.T, cmap='plasma', origin='lower', vmin=0, vmax=2)\n",
    "    axes[idx].set_title(f'Relative Uncertainty - {label}\\n(z={mid_z})', fontsize=12, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "    plt.colorbar(im, ax=axes[idx], fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.suptitle(f'Relative Uncertainty (Std / |Mean|) - Clipped to [0, 2]', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf830c1",
   "metadata": {},
   "source": [
    "## 12. Save Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168865e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally save results to HDF5\n",
    "save_results = True  # Set to True to save\n",
    "output_path = '/myhome/smartt/results/sparse_uncertainty_analysis.h5'\n",
    "\n",
    "if save_results:\n",
    "    print(f\"Saving results to {output_path}...\")\n",
    "    \n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with h5py.File(output_path, 'w') as f:\n",
    "        # Save reconstructions\n",
    "        f.create_dataset('all_reconstructions', data=all_reconstructions, compression='gzip')\n",
    "        f.create_dataset('mean_reconstruction', data=mean_reconstruction, compression='gzip')\n",
    "        f.create_dataset('std_reconstruction', data=std_reconstruction, compression='gzip')\n",
    "        f.create_dataset('ground_truth', data=ground_truth, compression='gzip')\n",
    "        \n",
    "        # Save indices\n",
    "        f.create_dataset('fixed_sparse_indices', data=fixed_sparse_indices)\n",
    "        for i, indices in enumerate(subsample_indices_list):\n",
    "            f.create_dataset(f'subsample_indices_{i}', data=indices)\n",
    "        \n",
    "        # Save metadata\n",
    "        f.attrs['ell_max'] = ell_max\n",
    "        f.attrs['num_experiments'] = num_experiments\n",
    "        f.attrs['num_projections_sparse'] = num_projections_sparse\n",
    "        f.attrs['num_subsamples'] = num_subsamples\n",
    "        f.attrs['total_projections'] = total_projections\n",
    "        f.attrs['volume_shape'] = volume_shape\n",
    "        f.attrs['num_coeffs'] = num_coeffs\n",
    "        f.attrs['seed'] = seed\n",
    "    \n",
    "    print(f\"Results saved successfully!\")\n",
    "else:\n",
    "    print(\"Results not saved (set save_results=True to save)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved results from HDF5\n",
    "load_results = False  # Set to True to load\n",
    "input_path = '/myhome/smartt/results/sparse_uncertainty_analysis.h5'\n",
    "\n",
    "if load_results:\n",
    "    print(f\"Loading results from {input_path}...\")\n",
    "    \n",
    "    with h5py.File(input_path, 'r') as f:\n",
    "        # Load reconstructions\n",
    "        all_reconstructions = f['all_reconstructions'][:]\n",
    "        mean_reconstruction = f['mean_reconstruction'][:]\n",
    "        std_reconstruction = f['std_reconstruction'][:]\n",
    "        ground_truth = f['ground_truth'][:]\n",
    "        \n",
    "        # Load indices\n",
    "        fixed_sparse_indices = f['fixed_sparse_indices'][:]\n",
    "        subsample_indices_list = []\n",
    "        for i in range(f.attrs['num_experiments']):\n",
    "            subsample_indices = f[f'subsample_indices_{i}'][:]\n",
    "            subsample_indices_list.append(subsample_indices)\n",
    "        \n",
    "        # Load metadata\n",
    "        ell_max = f.attrs['ell_max']\n",
    "        num_experiments = f.attrs['num_experiments']\n",
    "        num_projections_sparse = f.attrs['num_projections_sparse']\n",
    "        num_subsamples = f.attrs['num_subsamples']\n",
    "        total_projections = f.attrs['total_projections']\n",
    "        volume_shape = tuple(f.attrs['volume_shape'])\n",
    "        num_coeffs = f.attrs['num_coeffs']\n",
    "        seed = f.attrs['seed']\n",
    "    \n",
    "    print(f\"Results loaded successfully!\")\n",
    "    print(f\"\\nLoaded data:\")\n",
    "    print(f\"  all_reconstructions shape: {all_reconstructions.shape}\")\n",
    "    print(f\"  mean_reconstruction shape: {mean_reconstruction.shape}\")\n",
    "    print(f\"  std_reconstruction shape: {std_reconstruction.shape}\")\n",
    "    print(f\"  ground_truth shape: {ground_truth.shape}\")\n",
    "    print(f\"  Number of experiments: {num_experiments}\")\n",
    "    print(f\"  Fixed sparse subset: {len(fixed_sparse_indices)} projections\")\n",
    "    print(f\"  Subsample size: {num_subsamples} projections\")\n",
    "else:\n",
    "    print(\"Results not loaded (set load_results=True to load)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f428f5b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Ground Truth**: Computed using all 240 available projections\n",
    "2. **Fixed Sparse Subset**: 60 projections randomly selected and fixed\n",
    "3. **Multiple Experiments**: 20 reconstructions, each using 48 randomly sampled projections from the fixed subset\n",
    "4. **Uncertainty Quantification**: Standard deviation across experiments shows reconstruction uncertainty\n",
    "5. **Coefficient Analysis**: Different spherical harmonic coefficients show varying levels of uncertainty\n",
    "6. **Relative Uncertainty**: Normalized by signal strength to identify problematic regions\n",
    "\n",
    "Key findings:\n",
    "- Higher-order coefficients (larger ℓ values) typically show higher uncertainty\n",
    "- Regions with low signal show higher relative uncertainty\n",
    "- The standard deviation provides a measure of reconstruction stability given sparse sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3ac1b",
   "metadata": {},
   "source": [
    "## 13. Forward Project Reconstructions to Analyze Angular Variability\n",
    "\n",
    "We'll project each reconstruction through all projection angles and analyze which angles show the highest variability across experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3c96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_vecs = dc_full.geometry.probed_coordinates.vector[69:75]\n",
    "points3D = torch.tensor(subset_vecs).reshape(-1, 3)\n",
    "points3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "colors = torch.arange(len(subset_vecs)).repeat_interleave(24)\n",
    "colors = colors.reshape(-1)\n",
    "colors, torch.tensor(points3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be03248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Create 3D plot of probed coordinates\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create sphere surface\n",
    "u = np.linspace(0, 2 * np.pi, 50)\n",
    "v = np.linspace(0, np.pi, 50)\n",
    "x_sphere = np.outer(np.cos(u), np.sin(v))\n",
    "y_sphere = np.outer(np.sin(u), np.sin(v))\n",
    "z_sphere = np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "\n",
    "# Plot translucent sphere\n",
    "ax.plot_surface(x_sphere, y_sphere, z_sphere, color='cyan', alpha=0.1, edgecolor='none')\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('Translucent Sphere (Radius = 1)', fontsize=14, fontweight='bold')\n",
    "ax.set_box_aspect([1,1,1])\n",
    "\n",
    "# Plot the 3D points\n",
    "ax.scatter(points3D[:, 0], points3D[:, 1], points3D[:, 2], \n",
    "           c=colors, s=10, cmap='viridis', alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('X', fontsize=11)\n",
    "ax.set_ylabel('Y', fontsize=11)\n",
    "ax.set_zlabel('Z', fontsize=11)\n",
    "ax.set_title('Probed Coordinates in 3D Space', fontsize=14, fontweight='bold')\n",
    "ax.view_init(elev=20, azim=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total number of probed points: {len(points3D)}\")\n",
    "print(f\"Points shape: {points3D.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c72b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create projector using the full geometry from dc_full\n",
    "print(\"Creating projector with full geometry...\")\n",
    "projector_full = SAXSProjector(dc_full.geometry)\n",
    "\n",
    "# Create basis set for forward projection\n",
    "basis_set = SphericalHarmonics(ell_max=ell_max, probed_coordinates=dc_full.geometry.probed_coordinates)\n",
    "\n",
    "print(f\"Projector geometry:\")\n",
    "print(f\"  Number of projections: {len(dc_full.geometry.inner_angles)}\")\n",
    "print(f\"  Projection shape: {dc_full.geometry.projection_shape}\")\n",
    "print(f\"  Detector angles: {dc_full.geometry.detector_angles.shape}\")\n",
    "\n",
    "num_angles = len(dc_full.geometry.inner_angles)\n",
    "proj_shape = dc_full.geometry.projection_shape\n",
    "num_detector_angles = len(dc_full.geometry.detector_angles)\n",
    "\n",
    "print(f\"\\nExpected output shape per reconstruction: ({num_angles}, {proj_shape[0]}, {proj_shape[1]}, {num_detector_angles})\")\n",
    "print(f\"Expected output shape for all reconstructions: ({num_experiments}, {num_angles}, {proj_shape[0]}, {proj_shape[1]}, {num_detector_angles})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db947b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward project all reconstructions\n",
    "print(f\"\\nForward projecting {num_experiments} reconstructions through {num_angles} angles...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "# Pre-allocate array for all forward projections\n",
    "all_forward_projections = np.zeros(\n",
    "    (num_experiments, num_angles, proj_shape[0], proj_shape[1], num_detector_angles),\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "for exp_idx in tqdm(range(num_experiments), desc=\"Forward projecting\"):\n",
    "    reconstruction = all_reconstructions[exp_idx].astype(np.float64)\n",
    "    \n",
    "    # Forward project: projector.forward() then basis_set.forward()\n",
    "    spatial_projection = projector_full.forward(reconstruction)\n",
    "    forward_proj = basis_set.forward(spatial_projection)\n",
    "    \n",
    "    all_forward_projections[exp_idx] = forward_proj.astype(np.float32)\n",
    "    \n",
    "    # Clean up\n",
    "    del reconstruction, spatial_projection, forward_proj\n",
    "\n",
    "print(f\"\\nForward projections shape: {all_forward_projections.shape}\")\n",
    "print(f\"Expected shape: ({num_experiments}, {num_angles}, {proj_shape[0]}, {proj_shape[1]}, {num_detector_angles})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute standard deviation across experiments for each angle\n",
    "print(\"Computing variability across experiments for each projection angle...\")\n",
    "\n",
    "# Compute std across experiments (axis 0) for each angle\n",
    "# Result shape: (num_angles, proj_shape[0], proj_shape[1], num_detector_angles)\n",
    "std_per_angle = np.std(all_forward_projections, axis=0)\n",
    "\n",
    "# Compute total variability per angle (sum of variance across all pixels and detector angles)\n",
    "variability_per_angle = np.sum(std_per_angle**2, axis=(1, 2, 3))\n",
    "\n",
    "print(f\"\\nStandard deviation per angle shape: {std_per_angle.shape}\")\n",
    "print(f\"Variability per angle shape: {variability_per_angle.shape}\")\n",
    "print(f\"\\nVariability statistics:\")\n",
    "print(f\"  Mean: {np.mean(variability_per_angle):.4f}\")\n",
    "print(f\"  Median: {np.median(variability_per_angle):.4f}\")\n",
    "print(f\"  Min: {np.min(variability_per_angle):.4f}\")\n",
    "print(f\"  Max: {np.max(variability_per_angle):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find angles with highest and lowest variability\n",
    "num_top_angles = 20\n",
    "\n",
    "# Get indices sorted by variability\n",
    "sorted_indices = np.argsort(variability_per_angle)[::-1]  # Descending order\n",
    "\n",
    "# Top 20 most variable angles\n",
    "top_variable_indices = sorted_indices[:num_top_angles]\n",
    "top_variable_values = variability_per_angle[top_variable_indices]\n",
    "\n",
    "# Bottom 20 least variable angles\n",
    "least_variable_indices = sorted_indices[-num_top_angles:]\n",
    "least_variable_values = variability_per_angle[least_variable_indices]\n",
    "\n",
    "fixed_sparse_values = variability_per_angle[fixed_sparse_indices]\n",
    "\n",
    "print(f\"Top {num_top_angles} most variable angles:\")\n",
    "for i, (idx, val) in enumerate(zip(top_variable_indices, top_variable_values)):\n",
    "    print(f\"  {i+1}. Angle {idx}: variability = {val:.4f}\")\n",
    "\n",
    "print(f\"\\nTop {num_top_angles} least variable angles:\")\n",
    "for i, (idx, val) in enumerate(zip(least_variable_indices, least_variable_values)):\n",
    "    print(f\"  {i+1}. Angle {idx}: variability = {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5238d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variability as a function of angle index\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(variability_per_angle, 'o-', linewidth=1, markersize=3, alpha=0.7)\n",
    "ax.scatter(top_variable_indices, top_variable_values, color='red', s=50, \n",
    "           label=f'Top {num_top_angles} most variable', zorder=5)\n",
    "ax.scatter(least_variable_indices, least_variable_values, color='green', s=50,\n",
    "           label=f'Top {num_top_angles} least variable', zorder=5)\n",
    "\n",
    "ax.scatter(fixed_sparse_indices, fixed_sparse_values, color='blue', s=50,\n",
    "           label=f'Fixed Sparse Angles', zorder=5)\n",
    "\n",
    "ax.set_xlabel('Projection Angle Index', fontsize=12)\n",
    "ax.set_ylabel('Total Variability (Sum of Variance)', fontsize=12)\n",
    "ax.set_title('Variability Across Projection Angles', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a875ac",
   "metadata": {},
   "source": [
    "### 3D Visualization of High-Variability Angles\n",
    "\n",
    "Visualize the projection angles with the highest variability on a 3D sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad70de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rotation and tilt angles from geometry\n",
    "rotation_angles_rad = dc_full.geometry.inner_angles[:]\n",
    "tilt_angles_rad = list(np.pi/2 - np.array(dc_full.geometry.outer_angles))[:]\n",
    "\n",
    "# Convert to Cartesian coordinates on unit sphere\n",
    "r = 1\n",
    "x_all = r * np.sin(tilt_angles_rad) * np.cos(rotation_angles_rad)\n",
    "y_all = r * np.sin(tilt_angles_rad) * np.sin(rotation_angles_rad)\n",
    "z_all = r * np.cos(tilt_angles_rad)\n",
    "\n",
    "# Extract coordinates for high-variability angles\n",
    "x_high_var = x_all[top_variable_indices]\n",
    "y_high_var = y_all[top_variable_indices]\n",
    "z_high_var = z_all[top_variable_indices]\n",
    "\n",
    "print(f\"Plotted {len(x_all)} total angles\")\n",
    "print(f\"Highlighted {len(x_high_var)} high-variability angles in red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3D sphere plot showing all angles and highlighting high-variability ones\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create sphere surface\n",
    "u = np.linspace(0, 2 * np.pi, 100)\n",
    "v = np.linspace(0, np.pi, 100)\n",
    "X = r * np.outer(np.cos(u), np.sin(v))\n",
    "Y = r * np.outer(np.sin(u), np.sin(v))\n",
    "Z = r * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "\n",
    "# Plot sphere (semi-transparent)\n",
    "ax.plot_surface(X, Y, Z, color='lightblue', alpha=0.1)\n",
    "\n",
    "# Plot all projection angles (gray)\n",
    "ax.scatter(x_all, y_all, z_all, color='gray', s=20, alpha=0.5, label='All angles')\n",
    "\n",
    "# Highlight high-variability angles (red)\n",
    "ax.scatter(x_high_var, y_high_var, z_high_var, color='red', s=100, \n",
    "           alpha=0.9, edgecolors='darkred', linewidths=2,\n",
    "           label=f'Top {num_top_angles} highest variability')\n",
    "\n",
    "ax.set_xlabel('X', fontsize=10)\n",
    "ax.set_ylabel('Y', fontsize=10)\n",
    "ax.set_zlabel('Z', fontsize=10)\n",
    "ax.set_title('Projection Angles: High-Variability Highlighted', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.view_init(elev=10, azim=70)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a020a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare fixed sparse subset vs high-variability angles in 3D\n",
    "# Extract coordinates for fixed sparse subset angles\n",
    "x_sparse = x_all[fixed_sparse_indices]\n",
    "y_sparse = y_all[fixed_sparse_indices]\n",
    "z_sparse = z_all[fixed_sparse_indices]\n",
    "\n",
    "print(f\"Fixed sparse subset: {len(fixed_sparse_indices)} angles\")\n",
    "print(f\"Top high-variability: {len(top_variable_indices)} angles\")\n",
    "\n",
    "# Check overlap between fixed sparse subset and high-variability angles\n",
    "overlap = np.intersect1d(fixed_sparse_indices, top_variable_indices)\n",
    "print(f\"Overlap between fixed sparse subset and top {num_top_angles} high-variability: {len(overlap)} angles\")\n",
    "print(f\"Overlap indices: {overlap}\")\n",
    "\n",
    "# Create 3D sphere plot\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot sphere surface (semi-transparent)\n",
    "ax.plot_surface(X, Y, Z, color='lightblue', alpha=0.05)\n",
    "\n",
    "# Plot all projection angles (light gray, small)\n",
    "ax.scatter(x_all, y_all, z_all, color='lightgray', s=15, alpha=0.3, label='All angles')\n",
    "\n",
    "# Plot fixed sparse subset (blue)\n",
    "ax.scatter(x_sparse, y_sparse, z_sparse, color='blue', s=80, \n",
    "           alpha=0.7, edgecolors='darkblue', linewidths=1.5,\n",
    "           label=f'Fixed sparse subset ({len(fixed_sparse_indices)})')\n",
    "\n",
    "# Plot high-variability angles (red) - these will appear on top\n",
    "ax.scatter(x_high_var, y_high_var, z_high_var, color='red', s=120, \n",
    "           alpha=0.9, edgecolors='darkred', linewidths=2,\n",
    "           label=f'Top {num_top_angles} highest variability', marker='^')\n",
    "\n",
    "# Highlight overlap if any (yellow stars)\n",
    "if len(overlap) > 0:\n",
    "    x_overlap = x_all[overlap]\n",
    "    y_overlap = y_all[overlap]\n",
    "    z_overlap = z_all[overlap]\n",
    "    ax.scatter(x_overlap, y_overlap, z_overlap, color='yellow', s=150,\n",
    "               alpha=1.0, edgecolors='orange', linewidths=2,\n",
    "               label=f'Overlap ({len(overlap)})', marker='*', zorder=10)\n",
    "\n",
    "ax.set_xlabel('X', fontsize=11)\n",
    "ax.set_ylabel('Y', fontsize=11)\n",
    "ax.set_zlabel('Z', fontsize=11)\n",
    "ax.set_title(f'Projection Angles: Fixed Sparse Subset vs High-Variability Angles', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10, loc='upper left')\n",
    "ax.view_init(elev=10, azim=70)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another view focusing only on high-variability angles\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create sphere surface\n",
    "ax.plot_surface(X, Y, Z, color='lightgray', alpha=0.1)\n",
    "\n",
    "# Plot only high-variability angles with color scale based on variability\n",
    "scatter = ax.scatter(x_high_var, y_high_var, z_high_var, \n",
    "                     c=top_variable_values, s=200, cmap='hot',\n",
    "                     alpha=0.9, edgecolors='black', linewidths=1)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax, shrink=0.6, pad=0.1)\n",
    "cbar.set_label('Variability', fontsize=12)\n",
    "\n",
    "ax.set_xlabel('X', fontsize=10)\n",
    "ax.set_ylabel('Y', fontsize=10)\n",
    "ax.set_zlabel('Z', fontsize=10)\n",
    "ax.set_title(f'Top {num_top_angles} Highest-Variability Angles\\n(Color-coded by variability)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.view_init(elev=10, azim=70)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354cd0e",
   "metadata": {},
   "source": [
    "### Compare Projections at Most and Least Variable Angles\n",
    "\n",
    "Visualize the actual projection images at angles with highest and lowest variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c799c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few angles to visualize in detail\n",
    "num_angles_to_show = 3\n",
    "detector_angle_idx = 0  # Show one detector angle\n",
    "\n",
    "# Most variable angles\n",
    "high_var_angles = top_variable_indices[:num_angles_to_show]\n",
    "high_var_labels = [f\"Angle {idx}\\nVar={variability_per_angle[idx]:.2f}\" \n",
    "                   for idx in high_var_angles]\n",
    "\n",
    "# Least variable angles  \n",
    "low_var_angles = least_variable_indices[:num_angles_to_show]\n",
    "low_var_labels = [f\"Angle {idx}\\nVar={variability_per_angle[idx]:.2f}\" \n",
    "                  for idx in low_var_angles]\n",
    "\n",
    "print(f\"Visualizing detector angle index {detector_angle_idx}\")\n",
    "print(f\"\\nMost variable angles: {high_var_angles}\")\n",
    "print(f\"Least variable angles: {low_var_angles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d26cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot standard deviation projections for high-variability angles\n",
    "fig, axes = plt.subplots(1, num_angles_to_show, figsize=(18, 6))\n",
    "\n",
    "for i, (angle_idx, label) in enumerate(zip(high_var_angles, high_var_labels)):\n",
    "    std_proj = std_per_angle[angle_idx, :, :, detector_angle_idx]\n",
    "    \n",
    "    im = axes[i].imshow(std_proj.T, cmap='hot', origin='lower')\n",
    "    axes[i].set_title(f'High Variability\\n{label}', fontsize=11, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "    plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.suptitle(f'Standard Deviation of Projections - Most Variable Angles (Detector angle {detector_angle_idx})',\n",
    "             fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot standard deviation projections for low-variability angles\n",
    "fig, axes = plt.subplots(1, num_angles_to_show, figsize=(18, 6))\n",
    "\n",
    "for i, (angle_idx, label) in enumerate(zip(low_var_angles, low_var_labels)):\n",
    "    std_proj = std_per_angle[angle_idx, :, :, detector_angle_idx]\n",
    "    \n",
    "    im = axes[i].imshow(std_proj.T, cmap='hot', origin='lower')\n",
    "    axes[i].set_title(f'Low Variability\\n{label}', fontsize=11, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "    plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.suptitle(f'Standard Deviation of Projections - Least Variable Angles (Detector angle {detector_angle_idx})',\n",
    "             fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a924bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare mean projections from experiments vs ground truth for highest variability angle\n",
    "most_variable_angle = top_variable_indices[0]\n",
    "\n",
    "# Compute mean projection across experiments\n",
    "mean_projection = np.mean(all_forward_projections[:, most_variable_angle, :, :, detector_angle_idx], axis=0)\n",
    "\n",
    "# Get ground truth projection (need to project ground truth)\n",
    "print(f\"Computing ground truth projection for angle {most_variable_angle}...\")\n",
    "gt_spatial_proj = projector_full.forward(ground_truth.astype(np.float64))\n",
    "gt_forward_proj = basis_set.forward(gt_spatial_proj)\n",
    "gt_projection = gt_forward_proj[most_variable_angle, :, :, detector_angle_idx]\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "vmin = min(mean_projection.min(), gt_projection.min())\n",
    "vmax = max(mean_projection.max(), gt_projection.max())\n",
    "\n",
    "# Mean projection\n",
    "im0 = axes[0].imshow(mean_projection.T, cmap='viridis', vmin=vmin, vmax=vmax, origin='lower')\n",
    "axes[0].set_title(f'Mean Projection\\nAngle {most_variable_angle}', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Ground truth projection\n",
    "im1 = axes[1].imshow(gt_projection.T, cmap='viridis', vmin=vmin, vmax=vmax, origin='lower')\n",
    "axes[1].set_title(f'Ground Truth Projection\\nAngle {most_variable_angle}', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Difference\n",
    "diff = mean_projection - gt_projection\n",
    "im2 = axes[2].imshow(diff.T, cmap='RdBu_r', origin='lower',\n",
    "                     vmin=-np.abs(diff).max(), vmax=np.abs(diff).max())\n",
    "axes[2].set_title('Difference\\n(Mean - Ground Truth)', fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.suptitle(f'Most Variable Angle (#{most_variable_angle}, variability={variability_per_angle[most_variable_angle]:.2f})',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMSE between mean and ground truth projection: {np.mean((mean_projection - gt_projection)**2):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e2052f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p20639",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
