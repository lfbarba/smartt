"""
PyTorch Dataset implementation for tensor tomography reconstructions.

This module provides a Dataset class for loading and accessing tensor tomography
reconstruction data stored in HDF5 format.
"""

import h5py
import numpy as np
import torch
from pathlib import Path
from typing import Union, Optional, Tuple, Dict, Any
from torch.utils.data import Dataset


class ReconstructionDataset(Dataset):
    """
    PyTorch Dataset for tensor tomography reconstructions.
    
    This dataset loads 4D reconstruction tensors from an HDF5 file generated by
    the data_processing module. Each item is a 4D tensor of shape 
    (height, width, depth, num_coefficients) representing spherical harmonic
    coefficients at each voxel.
    
    Parameters
    ----------
    hdf5_path : str or Path
        Path to the HDF5 file containing reconstruction data.
    transform : callable, optional
        Optional transform to apply to each reconstruction tensor.
    load_in_memory : bool, default=False
        If True, loads all reconstructions into memory at initialization.
        If False, reads from disk on each __getitem__ call (slower but uses less memory).
    return_metadata : bool, default=False
        If True, __getitem__ returns a tuple (tensor, metadata_dict).
        If False, __getitem__ returns only the tensor.
    
    Attributes
    ----------
    num_samples : int
        Total number of reconstructions in the dataset.
    volume_shape : tuple
        Shape of the 3D volume (height, width, depth).
    num_coefficients : int
        Number of spherical harmonic coefficients.
    ell_max : int
        Maximum spherical harmonic degree.
    num_projections : int
        Number of projections used for each reconstruction.
    
    Examples
    --------
    >>> from smartt import ReconstructionDataset
    >>> from torch.utils.data import DataLoader
    >>> 
    >>> dataset = ReconstructionDataset('training_data.h5')
    >>> print(f"Dataset size: {len(dataset)}")
    >>> print(f"Volume shape: {dataset.volume_shape}")
    >>> print(f"Coefficients: {dataset.num_coefficients}")
    >>> 
    >>> # Get a single sample
    >>> reconstruction = dataset[0]
    >>> print(f"Reconstruction shape: {reconstruction.shape}")
    >>> 
    >>> # Use with DataLoader
    >>> dataloader = DataLoader(dataset, batch_size=4, shuffle=True)
    >>> for batch in dataloader:
    ...     print(f"Batch shape: {batch.shape}")
    ...     break
    """
    
    def __init__(
        self,
        hdf5_path: Union[str, Path],
        transform: Optional[callable] = None,
        load_in_memory: bool = False,
        return_metadata: bool = False
    ):
        """Initialize the ReconstructionDataset."""
        self.hdf5_path = Path(hdf5_path)
        self.transform = transform
        self.load_in_memory = load_in_memory
        self.return_metadata = return_metadata
        
        if not self.hdf5_path.exists():
            raise FileNotFoundError(f"HDF5 file not found: {self.hdf5_path}")
        
        # Load metadata
        with h5py.File(self.hdf5_path, 'r') as f:
            self.num_samples = f['reconstructions'].shape[0]
            self.volume_shape = tuple(f['reconstructions'].shape[1:4])
            self.num_coefficients = f['reconstructions'].shape[4]
            self.ell_max = int(f['ell_max'][()])
            self.num_projections = int(f['num_projections'][()])
            
            # Load additional metadata if available
            self.metadata = {}
            if 'num_iterations' in f:
                self.metadata['num_iterations'] = int(f['num_iterations'][()])
            if 'maxiter' in f:
                self.metadata['maxiter'] = int(f['maxiter'][()])
            if 'regularization_weight' in f:
                self.metadata['regularization_weight'] = float(f['regularization_weight'][()])
            if 'data_path' in f.attrs:
                self.metadata['source_data_path'] = f.attrs['data_path']
            
            # Optionally load projection indices
            if 'projection_indices' in f:
                self.projection_indices = f['projection_indices'][:]
            else:
                self.projection_indices = None
            
            # Load all data into memory if requested
            if self.load_in_memory:
                self.data = f['reconstructions'][:]
            else:
                self.data = None
    
    def __len__(self) -> int:
        """Return the number of reconstructions in the dataset."""
        return self.num_samples
    
    def __getitem__(self, idx: int) -> Union[torch.Tensor, Tuple[torch.Tensor, Dict[str, Any]]]:
        """
        Get a reconstruction tensor by index.
        
        Parameters
        ----------
        idx : int
            Index of the reconstruction to retrieve.
        
        Returns
        -------
        torch.Tensor or tuple
            If return_metadata=False: torch.Tensor of shape 
            (height, width, depth, num_coefficients).
            If return_metadata=True: tuple of (tensor, metadata_dict) where
            metadata_dict contains information about this reconstruction.
        """
        if idx < 0 or idx >= self.num_samples:
            raise IndexError(f"Index {idx} out of range [0, {self.num_samples})")
        
        # Load data
        if self.load_in_memory:
            reconstruction = self.data[idx]
        else:
            with h5py.File(self.hdf5_path, 'r') as f:
                reconstruction = f['reconstructions'][idx]
        
        # Convert to torch tensor
        reconstruction = torch.from_numpy(reconstruction.astype(np.float32))
        
        # Apply transform if provided
        if self.transform is not None:
            reconstruction = self.transform(reconstruction)
        
        # Return with or without metadata
        if self.return_metadata:
            item_metadata = {
                'index': idx,
                'num_projections': self.num_projections,
                'ell_max': self.ell_max,
            }
            if self.projection_indices is not None:
                item_metadata['projection_indices'] = self.projection_indices[idx]
            return reconstruction, item_metadata
        else:
            return reconstruction
    
    def get_metadata(self) -> Dict[str, Any]:
        """
        Get dataset-level metadata.
        
        Returns
        -------
        dict
            Dictionary containing dataset metadata including num_samples,
            volume_shape, num_coefficients, ell_max, num_projections, etc.
        """
        meta = {
            'num_samples': self.num_samples,
            'volume_shape': self.volume_shape,
            'num_coefficients': self.num_coefficients,
            'ell_max': self.ell_max,
            'num_projections': self.num_projections,
            'hdf5_path': str(self.hdf5_path),
        }
        meta.update(self.metadata)
        return meta
    
    def get_projection_indices(self, idx: int) -> Optional[np.ndarray]:
        """
        Get the projection indices used for a specific reconstruction.
        
        Parameters
        ----------
        idx : int
            Index of the reconstruction.
        
        Returns
        -------
        np.ndarray or None
            Array of projection indices, or None if not available.
        """
        if self.projection_indices is None:
            return None
        if idx < 0 or idx >= self.num_samples:
            raise IndexError(f"Index {idx} out of range [0, {self.num_samples})")
        return self.projection_indices[idx]
    
    def __repr__(self) -> str:
        """Return string representation of the dataset."""
        return (
            f"ReconstructionDataset(\n"
            f"  hdf5_path={self.hdf5_path},\n"
            f"  num_samples={self.num_samples},\n"
            f"  volume_shape={self.volume_shape},\n"
            f"  num_coefficients={self.num_coefficients},\n"
            f"  ell_max={self.ell_max},\n"
            f"  num_projections={self.num_projections},\n"
            f"  load_in_memory={self.load_in_memory}\n"
            f")"
        )


class ReconstructionDatasetSubset(Dataset):
    """
    A subset of ReconstructionDataset with specific coefficient channels.
    
    This is useful when you want to work with only a subset of spherical harmonic
    coefficients, for example, only the first few orders.
    
    Parameters
    ----------
    base_dataset : ReconstructionDataset
        The base dataset to create a subset from.
    coefficient_indices : array-like
        Indices of coefficients to include in the subset.
    
    Examples
    --------
    >>> dataset = ReconstructionDataset('training_data.h5')
    >>> # Only use first 9 coefficients (up to ell=2)
    >>> subset = ReconstructionDatasetSubset(dataset, coefficient_indices=range(9))
    >>> print(f"Subset shape: {subset[0].shape}")
    """
    
    def __init__(
        self,
        base_dataset: ReconstructionDataset,
        coefficient_indices: Union[list, np.ndarray, range]
    ):
        """Initialize the subset dataset."""
        self.base_dataset = base_dataset
        self.coefficient_indices = np.array(list(coefficient_indices))
        
        # Validate indices
        max_idx = self.base_dataset.num_coefficients
        if np.any(self.coefficient_indices >= max_idx) or np.any(self.coefficient_indices < 0):
            raise ValueError(
                f"Coefficient indices must be in range [0, {max_idx}), "
                f"got range [{self.coefficient_indices.min()}, {self.coefficient_indices.max()}]"
            )
    
    def __len__(self) -> int:
        """Return the number of samples (same as base dataset)."""
        return len(self.base_dataset)
    
    def __getitem__(self, idx: int) -> torch.Tensor:
        """Get a reconstruction with only selected coefficient channels."""
        reconstruction = self.base_dataset[idx]
        if isinstance(reconstruction, tuple):
            reconstruction, metadata = reconstruction
            subset_reconstruction = reconstruction[..., self.coefficient_indices]
            return subset_reconstruction, metadata
        else:
            return reconstruction[..., self.coefficient_indices]
    
    def __repr__(self) -> str:
        """Return string representation."""
        return (
            f"ReconstructionDatasetSubset(\n"
            f"  base_dataset={self.base_dataset.__class__.__name__},\n"
            f"  num_samples={len(self)},\n"
            f"  selected_coefficients={len(self.coefficient_indices)}/{self.base_dataset.num_coefficients}\n"
            f")"
        )


if __name__ == "__main__":
    # Example usage
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python dataset.py <hdf5_file>")
        sys.exit(1)
    
    hdf5_path = sys.argv[1]
    
    print("Loading dataset...")
    dataset = ReconstructionDataset(hdf5_path)
    print(dataset)
    print("\nMetadata:")
    for key, value in dataset.get_metadata().items():
        print(f"  {key}: {value}")
    
    print(f"\nFirst reconstruction shape: {dataset[0].shape}")
    print(f"First reconstruction dtype: {dataset[0].dtype}")
    
    if dataset.projection_indices is not None:
        indices = dataset.get_projection_indices(0)
        print(f"\nProjection indices for first sample: {indices}")
